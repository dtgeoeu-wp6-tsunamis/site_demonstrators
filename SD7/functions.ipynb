{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64f6fafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import numpy.matlib as npm\n",
    "import utm\n",
    "# import ast\n",
    "import copy\n",
    "import math\n",
    "import scipy\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import distributions\n",
    "# from operator import itemgetter\n",
    "# from numba import jit\n",
    "import cartopy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import json\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479e0567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "        \"\"\"\n",
    "        Calculate the great circle distance between two points\n",
    "        on the earth (specified in decimal degrees)\n",
    "        \"\"\"\n",
    "        # convert decimal degrees to radians\n",
    "        lon1, lat1, lon2, lat2 = map(math.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "        # haversine formula\n",
    "        dlon = lon2 - lon1\n",
    "        dlat = lat2 - lat1\n",
    "        a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\n",
    "        c = 2 * math.asin(math.sqrt(a))\n",
    "        r = 6371 # Radius of earth in kilometers.\n",
    "        return c * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6446bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_setup():\n",
    "    proj = cartopy.crs.PlateCarree()\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "    # ax = plt.axes(projection=cartopy.crs.Mercator())\n",
    "    usemap_proj = cartopy.crs.PlateCarree(central_longitude=180)\n",
    "    ax = plt.axes(projection=usemap_proj)\n",
    "\n",
    "    coastline = cartopy.feature.GSHHSFeature(scale='low', levels=[1])\n",
    "    # coastline = cartopy.feature.GSHHSFeature(scale='high', levels=[1])\n",
    "    ax.add_feature(coastline, edgecolor='#000000', facecolor='#cccccc', linewidth=1)\n",
    "    ax.add_feature(cartopy.feature.BORDERS.with_scale('50m'))\n",
    "    ax.add_feature(cartopy.feature.STATES.with_scale('50m'))\n",
    "    ax.add_feature(cartopy.feature.OCEAN.with_scale('50m'))\n",
    "    gl = ax.gridlines(crs=proj, draw_labels=True, linewidth=1,\n",
    "                        color=\"#ffffff\", alpha=0.5, linestyle='-')\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "    gl.bottom_labels = True\n",
    "    gl.left_labels = True\n",
    "    gl.xformatter = cartopy.mpl.gridliner.LONGITUDE_FORMATTER\n",
    "    gl.yformatter = cartopy.mpl.gridliner.LATITUDE_FORMATTER\n",
    "    gl.xlabel_style = {'size': 14}\n",
    "    gl.ylabel_style = {'size': 14}\n",
    "\n",
    "    return ax, proj\n",
    "\n",
    "\n",
    "def plot_pois(pois_coords, ind, event_dict):\n",
    "\n",
    "    ev_lon = event_dict['lon']\n",
    "    ev_lat = event_dict['lat']\n",
    "\n",
    "    ax, proj = map_setup()\n",
    "    \n",
    "    ax.plot(pois_coords[ind,0], pois_coords[ind,1], markerfacecolor=\"#0ba518\", marker=\"o\",\n",
    "                linewidth=0, markeredgecolor=\"#000000\",\n",
    "                transform=proj)#, zorder=10)\n",
    "\n",
    "    ax.plot(ev_lon, ev_lat, linewidth=0, marker='*', markersize=10,\n",
    "            markerfacecolor='red', markeredgecolor='#000000',\n",
    "            transform=proj)\n",
    "    \n",
    "    # ax.set_extent([19., 30.5, 35.5, 41.5], crs=proj)\n",
    "\n",
    "    ax.set_xlabel(r'Longitude ($^\\circ$)', fontsize=14)\n",
    "    ax.set_ylabel(r'Latitude ($^\\circ$)', fontsize=14)\n",
    "\n",
    "def plot_barycenters(bs_coords, prob, event_dict):\n",
    "\n",
    "    # fig,axs = plt.subplots(2,1,figsize=(20,20),subplot_kw={'projection': cartopy.crs.Mercator()})\n",
    "    # fig.set_tight_layout(True)\n",
    "    ev_lon = event_dict['lon']\n",
    "    ev_lat = event_dict['lat']\n",
    "\n",
    "    ax, proj = map_setup()\n",
    " \n",
    "    lonlat_list=[list(x) for x in set(tuple(x) for x in bs_coords)]\n",
    "    nloc=len(lonlat_list)\n",
    " \n",
    "    sumprob=[]\n",
    "    for iloc in range(nloc):\n",
    "        locxy=lonlat_list[iloc]\n",
    "        isel = [i for i, x in enumerate(list(bs_coords)) if np.allclose(x, locxy)]\n",
    "        # isel = [i for i, x in enumerate(list(bs_coords)) if x == locxy]\n",
    "        #print(len(isel))\n",
    "        tmplist=[prob[i] for i in isel]\n",
    "        sumprob.append(sum(tmplist))\n",
    "    lon = [el[0] for el in lonlat_list]\n",
    "    lat = [el[1] for el in lonlat_list]\n",
    " \n",
    "    # lon = bs_coords[:,0] \n",
    "    # lat = bs_coords[:,1]\n",
    "    cmap = ax.scatter(lon,lat,s=30, transform=proj,edgecolors='k',c=sumprob,cmap=plt.cm.plasma)#, label=labels[ic], c=colors[ic])\n",
    "    cbar = plt.colorbar(cmap,ax=ax,extend='both',extendfrac='auto',aspect=30,format='%.0e',pad=0.02,\n",
    "                 label='Cumulated Probability (for each barycenter)',shrink=0.8)\n",
    " \n",
    "    ax.plot(ev_lon, ev_lat, linewidth=0, marker='*', markersize=10,\n",
    "            markerfacecolor='red', markeredgecolor='#000000',\n",
    "            transform=proj)\n",
    "     \n",
    "    ax.set_extent([140, 150, 35, 45], crs=proj)\n",
    "\n",
    "    cbar.locator = ticker.MaxNLocator(nbins=10)\n",
    "    cbar.update_ticks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5703c4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions are copied from the ptf_pre_load.py file\n",
    "\n",
    "def load_intensity_thresholds(data_folder):\n",
    "    \"\"\"\n",
    "    READ THRESHOLDS\n",
    "    \"\"\"\n",
    "    \n",
    "    intensity_thresholds = os.path.join(data_folder, 'intensity_thresholds.npy')\n",
    "\n",
    "    ith = np.load(intensity_thresholds, allow_pickle=True)\n",
    "    intensity_measure = ith.item().keys()\n",
    "    thresholds = ith.item()[list(intensity_measure)[0]]\n",
    "\n",
    "    return thresholds, intensity_measure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afcca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions are copied from the ptf_scaling_laws.py file\n",
    "def scalinglaw_WC(**kwargs):\n",
    "    '''\n",
    "    Scaling law from Wells&Coppersmith (1994)\n",
    "    '''\n",
    "\n",
    "    mag        = kwargs.get('mag', None)\n",
    "    type_scala = kwargs.get('type_scala', None)\n",
    "\n",
    "    if (type_scala == 'M2L'):\n",
    "        a =-2.440\n",
    "        b =0.590\n",
    "        y = 10.**(a+b*mag)\n",
    "\n",
    "    elif (type_scala == 'M2W'):\n",
    "        a=-1.010\n",
    "        b=0.320\n",
    "        y = 10.**(a+b*mag)\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"Scaling law in scalinglaw_WC not recognized. Exit!\")\n",
    "        #print(\"Scaling law in scalinglaw_WC not recognized. Exit!\")\n",
    "        #sys.exit()\n",
    "\n",
    "    return y\n",
    "\n",
    "def scalinglaw_Murotani(**kwargs):\n",
    "    '''\n",
    "    Scaling law from Murotani et al (2013)\n",
    "    '''\n",
    "\n",
    "    mag        = kwargs.get('mag', None)\n",
    "    type_scala = kwargs.get('type_scala', None)\n",
    "\n",
    "    a    = -3.806\n",
    "    b    = 1.000\n",
    "    Area = 10**(a+b*mag)\n",
    "\n",
    "    if (type_scala == 'M2L'):\n",
    "        y = math.sqrt(2.5*Area)/2.5\n",
    "\n",
    "    elif (type_scala == 'M2W'):\n",
    "        y = math.sqrt(2.5*Area)\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"Scaling law in scalinglaw_Murotani not recognized. Exit!\")\n",
    "        #print(\"Scaling law in scalinglaw_Murotani not recognized. Exit!\")\n",
    "        #sys.exit()\n",
    "\n",
    "    return y\n",
    "\n",
    "def mag_to_l_BS(**kwargs):\n",
    "\n",
    "    mag = kwargs.get('mag', None)\n",
    "    out = 1000.0 * scalinglaw_WC(mag=mag, type_scala='M2L')\n",
    "\n",
    "    return out\n",
    "\n",
    "def mag_to_w_BS(**kwargs):\n",
    "\n",
    "    mag = kwargs.get('mag', None)\n",
    "    out = 1000.0 * scalinglaw_WC(mag=mag, type_scala='M2W')\n",
    "\n",
    "    return out\n",
    "\n",
    "def mag_to_l_PS(**kwargs):\n",
    "\n",
    "    mag = kwargs.get('mag', None)\n",
    "    out = 1000.0 * scalinglaw_Murotani(mag=mag, type_scala='M2W')\n",
    "\n",
    "    return out\n",
    "\n",
    "def correct_BS_horizontal_position(**kwargs):\n",
    "\n",
    "    mag = kwargs.get('mag', None)\n",
    "    out = 0.5 * mag_to_l_BS(mag=mag)\n",
    "\n",
    "    return out\n",
    "\n",
    "def correct_PS_horizontal_position(**kwargs):\n",
    "\n",
    "    mag = kwargs.get('mag', None)\n",
    "    out = 0.5 * mag_to_l_PS(mag=mag)\n",
    "\n",
    "    return out\n",
    " \n",
    "def correct_BS_vertical_position(**kwargs):\n",
    "\n",
    "    mag = kwargs.get('mag', None)\n",
    "    out = math.sin(math.pi/4)*0.5 * mag_to_w_BS(mag=mag)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ff1966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions are copied from the ptf_mix_utilities.py file\n",
    "\n",
    "def NormMultiDvec(**kwargs):\n",
    "\n",
    "    \"\"\"\n",
    "    # Here mu and sigma, already inserted into ee dictionary\n",
    "    # Coordinates in utm\n",
    "    mu = tmpmu =PosMean_3D = [EarlyEst.lonUTM,EarlyEst.latUTM,EarlyEst.Dep*1.E3]\n",
    "    Sigma = tmpCOV = EarlyEst.PosCovMat_3D = [EarlyEst.PosSigmaXX EarlyEst.PosSigmaXY EarlyEst.PosSigmaXZ; ...\n",
    "                         EarlyEst.PosSigmaXY EarlyEst.PosSigmaYY EarlyEst.PosSigmaYZ; ...\n",
    "                         EarlyEst.PosSigmaXZ EarlyEst.PosSigmaYZ EarlyEst.PosSigmaZZ];\n",
    "    mu =     np.array([ee['lon'], ee['lat'], ee['depth']*1000.0])\n",
    "    sigma =  np.array([[ee['cov_matrix']['XX'], ee['cov_matrix']['XY'], ee['cov_matrix']['XZ']], \\\n",
    "                       [ee['cov_matrix']['XY'], ee['cov_matrix']['YY'], ee['cov_matrix']['YZ']], \\\n",
    "                       [ee['cov_matrix']['XZ'], ee['cov_matrix']['YZ'], ee['cov_matrix']['ZZ']]])\n",
    "    \"\"\"\n",
    "\n",
    "    x     = kwargs.get('x', None)\n",
    "    mu    = kwargs.get('mu', None)\n",
    "    sigma = kwargs.get('sigma', None)\n",
    "\n",
    "    n = len(mu)\n",
    "\n",
    "    #mu = np.reshape(mu,(3,1))\n",
    "    mu = np.reshape(mu,(n,1))\n",
    "    t1  = (2 * math.pi)**(-1*len(mu)/2)\n",
    "    t2  = 1 / math.sqrt(np.linalg.det(sigma))\n",
    "    #c1  = npm.repmat(mu, 1, np.shape(mu)[0])\n",
    "    c1  = npm.repmat(mu, 1, len(x))\n",
    "    c11 = (x - c1.transpose()).transpose()\n",
    "    c12 = x - c1.transpose()\n",
    "\n",
    "    d  = np.linalg.lstsq(sigma, c11, rcond=None)[0]\n",
    "    e = np.dot(c12, d)\n",
    "    f = np.multiply(-0.5,np.diag(e))\n",
    "    g = np.exp(f)\n",
    "    h = t1 * t2 * g\n",
    "\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3634bd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions are copied from the ptf_load_event.py file\n",
    "def int_quake_cat2dict(json_object):\n",
    "\n",
    "    d = dict()\n",
    "\n",
    "    # Event Ids\n",
    "    try:\n",
    "        origin_id =  str(json_object['features'][0]['properties']['originid'])\n",
    "    except:\n",
    "        origin_id =  str(json_object['features'][0]['properties']['originId'])\n",
    "\n",
    "    event_id      =  str(json_object['features'][0]['properties']['eventId'])\n",
    "    # author        =  str(json_object['features'][0]['properties']['author'])\n",
    "    # version       =  str(json_object['features'][0]['properties']['version'])\n",
    "\n",
    "    # Epicenter informations\n",
    "    lon           =  float(json_object['features'][0]['geometry']['coordinates'][0])\n",
    "    lat           =  float(json_object['features'][0]['geometry']['coordinates'][1])\n",
    "    depth         =  float(json_object['features'][0]['geometry']['coordinates'][2])\n",
    "    OT            =  str(json_object['features'][0]['properties']['time'])\n",
    "    ev_type       =  str(json_object['features'][0]['properties']['type'])\n",
    "    mag_type      =  str(json_object['features'][0]['properties']['magType'])\n",
    "    place          =  str(json_object['features'][0]['properties']['place'])\n",
    "\n",
    "    #utm conversion\n",
    "    ee_utm = utm.from_latlon(lat, lon)\n",
    "\n",
    "    # Specific Mag percentiles and covariant cov_matrix\n",
    "    mag_percentiles = json_object['features'][0]['properties']['mag_percentiles']\n",
    "    cov_matrix      = json_object['features'][0]['properties']['cov_matrix']\n",
    "    \n",
    "    pos_Sigma = cov_matrix.copy() #json_string['features'][0]['properties']['cov_matrix']\n",
    "\n",
    "    cov_matrix['XX'] = float(cov_matrix['XX'])\n",
    "    cov_matrix['XY'] = float(cov_matrix['XY'])\n",
    "    cov_matrix['XZ'] = float(cov_matrix['XZ'])\n",
    "    cov_matrix['YY'] = float(cov_matrix['YY'])\n",
    "    cov_matrix['YZ'] = float(cov_matrix['YZ'])\n",
    "    cov_matrix['ZZ'] = float(cov_matrix['ZZ'])\n",
    "\n",
    "    pos_Sigma['XX']  = float(pos_Sigma['XX']) * 1e6\n",
    "    pos_Sigma['XY']  = float(pos_Sigma['XY']) * 1e6\n",
    "    pos_Sigma['XZ']  = float(pos_Sigma['XZ']) * 1e6\n",
    "    pos_Sigma['YY']  = float(pos_Sigma['YY']) * 1e6\n",
    "    pos_Sigma['YZ']  = float(pos_Sigma['YZ']) * 1e6\n",
    "    pos_Sigma['ZZ']  = float(pos_Sigma['ZZ']) * 1e6\n",
    "\n",
    "    mag_percentiles['p16']  = float(mag_percentiles['p16'])\n",
    "    mag_percentiles['p50']  = float(mag_percentiles['p50'])\n",
    "    mag_percentiles['p84']  = float(mag_percentiles['p84'])\n",
    "    mag_sigma = 0.5 * (mag_percentiles['p84'] - mag_percentiles['p16'])\n",
    "\n",
    "    d['eventid']        = event_id\n",
    "    d['originid']       = origin_id\n",
    "    d['lat']            = lat\n",
    "    d['lon']            = lon\n",
    "    d['depth']          = depth\n",
    "    d['ot']             = OT\n",
    "    d['mag']            = mag_percentiles['p50']\n",
    "    d['mag_percentiles'] = mag_percentiles\n",
    "    d['MagSigma']        = mag_sigma\n",
    "    d['type']           = ev_type\n",
    "    d['mag_type']       = mag_type\n",
    "    d['ee_utm']         = ee_utm\n",
    "    d['place']          = place\n",
    "\n",
    "    # d['version']        = \"%03d\" % (float(version))\n",
    "    # d['author']         = author\n",
    "    # d['area']           = area\n",
    "    # d['area_geo']       = area_geo\n",
    "    # d['mag']            = mag\n",
    "    # d['mag_values']     = mag_values\n",
    "    # d['mag_counts']     = mag_counts\n",
    "    # d['ct']             = creation_time\n",
    "    # d['ot_year']        = origin_year\n",
    "    # d['ot_month']       = origin_month\n",
    "    # d['ot_day']         = origin_day\n",
    "\n",
    "    d['cov_matrix']      = cov_matrix\n",
    "    d['pos_Sigma']       = pos_Sigma\n",
    "\n",
    "    d['ee_PosCovMat_2d'] = np.array([[cov_matrix['XX'], cov_matrix['XY']], \\\n",
    "                                     [cov_matrix['XY'], cov_matrix['YY']]])\n",
    "    d['PosMean_2d']      = np.array([d['ee_utm'][0], \\\n",
    "                                     d['ee_utm'][1]])\n",
    "    d['PosCovMat_3d']    = np.array([[cov_matrix['XX'], cov_matrix['XY'], cov_matrix['XZ']], \\\n",
    "                                     [cov_matrix['XY'], cov_matrix['YY'], cov_matrix['YZ']], \\\n",
    "                                     [cov_matrix['XZ'], cov_matrix['YZ'], cov_matrix['ZZ']]])\n",
    "    d['PosCovMat_3dm']    = d['PosCovMat_3d']*1000000\n",
    "    d['PosMean_3d']      = np.array([d['ee_utm'][0], \\\n",
    "                                     d['ee_utm'][1], \\\n",
    "                                     d['depth'] * 1000.0])\n",
    "\n",
    "    # d['root_name']       = str(d['ot_year']) + str(d['ot_month']) + str(d['ot_day']) + '_' + \\\n",
    "    #                        d['area']\n",
    "    #                        #str(d['eventid']) + '_' + str(d['version']) + '_' + d['area']\n",
    "\n",
    "    return d\n",
    "\n",
    "def compute_position_sigma_lat_lon(event_parameters):\n",
    "    \"\"\"\n",
    "    REFERENCE LAT = YY\n",
    "    REFERENCE LON = XX\n",
    "    \"\"\"\n",
    "\n",
    "    bs_mag_max          = 8.1\n",
    "\n",
    "    sigma               = event_parameters['sigma']\n",
    "    event_mag           = event_parameters['mag_percentiles']['p50']\n",
    "    event_mag_max       = event_parameters['mag_percentiles']['p50'] + \\\n",
    "                          event_parameters['MagSigma'] * sigma\n",
    "    event_mag_sigma     = event_parameters['MagSigma']\n",
    "\n",
    "    event_cov_xx        = event_parameters['pos_Sigma']['XX']\n",
    "    event_cov_xy        = event_parameters['pos_Sigma']['XY']\n",
    "    event_cov_yy        = event_parameters['pos_Sigma']['YY']\n",
    "\n",
    "\n",
    "    mag_to_correct      = min(bs_mag_max, event_mag_max)\n",
    "\n",
    "    delta_position_BS_h = correct_BS_horizontal_position(mag=mag_to_correct)\n",
    "    delta_position_PS_h = correct_PS_horizontal_position(mag=event_mag + sigma * event_mag_sigma)\n",
    "\n",
    "    position_BS_sigma_yy  = math.sqrt(abs(event_cov_yy)) + delta_position_BS_h\n",
    "    position_BS_sigma_xx  = math.sqrt(abs(event_cov_xx)) + delta_position_BS_h\n",
    "    position_BS_sigma_xy  = math.sqrt(abs(event_cov_xy)) + delta_position_BS_h\n",
    "\n",
    "    event_parameters['position_BS_sigma_yy'] = position_BS_sigma_yy\n",
    "    event_parameters['position_BS_sigma_xx'] = position_BS_sigma_xx\n",
    "    event_parameters['position_BS_sigma_xy'] = position_BS_sigma_xy\n",
    "\n",
    "    position_PS_sigma_yy  = math.sqrt(abs(event_cov_yy)) + delta_position_PS_h\n",
    "    position_PS_sigma_xx  = math.sqrt(abs(event_cov_xx)) + delta_position_PS_h\n",
    "    position_PS_sigma_xy  = math.sqrt(abs(event_cov_xy)) + delta_position_PS_h\n",
    "\n",
    "    event_parameters['position_PS_sigma_yy'] = position_PS_sigma_yy\n",
    "    event_parameters['position_PS_sigma_xx'] = position_PS_sigma_xx\n",
    "    event_parameters['position_PS_sigma_xy'] = position_PS_sigma_xy\n",
    "\n",
    "    return event_parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339c012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions are copied from the ptf_define_ensemble_global.py file\n",
    "def select_magnitude(event_parameters, magnitude_values, sigma):\n",
    "    \"\"\"\n",
    "    Selecting magnitude values to create the ensemble.\n",
    "    If magnitude distribution is provided in json file then the values \n",
    "    in the key [mag_values] are used. \n",
    "    Otherwise, magnitude ranges are defined from the uncertainty provided \n",
    "    in the key parameter [mag_percentiles]\n",
    "    \n",
    "    \"\"\"\n",
    "    print('--> Selecting magnitude values')\n",
    "\n",
    "    min_mag  = event_parameters['mag'] - event_parameters['MagSigma'] * sigma\n",
    "    max_mag  = event_parameters['mag'] + event_parameters['MagSigma'] * sigma\n",
    "\n",
    "    magnitudes = magnitude_values[(magnitude_values >= min_mag) & (magnitude_values <= max_mag)]\n",
    "    idx = np.where((magnitude_values >= min_mag) & (magnitude_values <= max_mag))\n",
    "    if magnitudes.size == 0:\n",
    "        idx = np.array((np.abs(magnitude_values-max_mag)).argmin())\n",
    "        magnitudes = np.array([magnitude_values[idx]])\n",
    "\n",
    "    print('    Number of magnitude values = ' + str(len(magnitudes)))\n",
    "    print('    Magnitudes selected: ' + str(magnitudes))\n",
    "\n",
    "    return magnitudes, idx\n",
    "\n",
    "def discretized_position(ellipse, step):\n",
    "\n",
    "    print('--> Discretizing positions')\n",
    "\n",
    "    utm_x_min = np.amin(ellipse[:,1])\n",
    "    utm_x_max = np.amax(ellipse[:,1])\n",
    "    utm_y_min = np.amin(ellipse[:,0])\n",
    "    utm_y_max = np.amax(ellipse[:,0])\n",
    "    utm_x = np.arange(utm_x_min, utm_x_max + step, step)\n",
    "    utm_y = np.arange(utm_y_min, utm_y_max + step, step)\n",
    "    \n",
    "    print('    Number of points along x= ' + str(len(utm_x)))\n",
    "    print('    Number of points along y= ' + str(len(utm_y)))\n",
    "\n",
    "    return utm_x, utm_y\n",
    "\n",
    "def discretized_depth(z, step):\n",
    "\n",
    "    print('--> Discretizing depths')\n",
    "\n",
    "    min_depth = np.amin(z)\n",
    "    max_depth = np.amax(z)\n",
    "\n",
    "    depth = np.arange(min_depth, max_depth + step, step)\n",
    "    print('    Number of points along z= ' + str(len(depth)))\n",
    "    \n",
    "    return depth\n",
    "\n",
    "def create_grid3d(event_parameters, ensemble): \n",
    "    \"\"\"\n",
    "    Creation of grid 3d of position in utm (x, y, z) and conversion to geographic coordinates (lon, lat).\n",
    "    In ensemble['grid_3d'] points are ordered as follows: x1,y1,z1; x1,y2,z1; ...; x2,y1,z1;...\n",
    "    \"\"\"\n",
    "\n",
    "    print('--> Creating grid 3d')\n",
    "\n",
    "    zone_number = event_parameters['ee_utm'][2]\n",
    "    zone_letter = event_parameters['ee_utm'][3]\n",
    "\n",
    "    position_x = ensemble['position_utm_x']\n",
    "    position_y = ensemble['position_utm_y']\n",
    "    depth      = ensemble['depth']\n",
    "\n",
    "    xx_3d, yy_3d, zz_3d = np.meshgrid(position_x, position_y, depth, indexing='xy')\n",
    "    xx_3d               = xx_3d.flatten('F')\n",
    "    yy_3d               = yy_3d.flatten('F')\n",
    "    zz_3d               = zz_3d.flatten('F')\n",
    "    grid_3d             = np.array([xx_3d, yy_3d, zz_3d]).transpose()\n",
    "\n",
    "    # geo_coord = np.array(utm.to_latlon(grid_3d[:,0], grid_3d[:,1], zone_number, zone_letter))\n",
    "    easting = copy.deepcopy(grid_3d[:,0])\n",
    "    northing = copy.deepcopy(grid_3d[:,1])\n",
    "    geo_coord = np.array(utm.to_latlon(easting, northing, zone_number, zone_letter))\n",
    "\n",
    "    # print(geo_coord.shape, grid_3d.shape)\n",
    "    print('    Number of grid points = ' + str(grid_3d.shape[0]))\n",
    "    \n",
    "    return grid_3d, geo_coord[1,:], geo_coord[0,:]\n",
    "\n",
    "def discretized_mechanism(fm, stk_step, stk_sigma, dip_step, dip_sigma, rake_step, rake_sigma):\n",
    "    \n",
    "    print('--> Discretizing strike, dip, and rake values')\n",
    "\n",
    "    #discretizing strike angle\n",
    "    stk_tmp = fm['np1']['strike']\n",
    "    stk1 = np.arange(stk_tmp - stk_sigma, stk_tmp + stk_sigma + 1, stk_step)\n",
    "    ind1 = np.argwhere(stk1 < 0)\n",
    "    stk1[ind1] = 180. - stk1[ind1]\n",
    "    stk_tmp = fm['np2']['strike']\n",
    "    stk2 = np.arange(stk_tmp - stk_sigma, stk_tmp + stk_sigma + 1, stk_step)\n",
    "    ind2 = np.argwhere(stk2 < 0)\n",
    "    stk2[ind2] = 180. - stk2[ind2]\n",
    "\n",
    "    #discretizing dip angle\n",
    "    #TODO BE CAREFUL TO NEGATIVE VALUES OF DIP\n",
    "    dip_tmp = fm['np1']['dip']\n",
    "    dip1 = np.arange(dip_tmp - dip_sigma, dip_tmp + dip_sigma + 1, dip_step)\n",
    "    dip_tmp = fm['np2']['dip']\n",
    "    dip2 = np.arange(dip_tmp - dip_sigma, dip_tmp + dip_sigma + 1, dip_step)\n",
    "\n",
    "    #discretizing rake angle\n",
    "    rake_tmp = fm['np1']['rake']\n",
    "    rake1 = np.arange(rake_tmp - rake_sigma, rake_tmp + rake_sigma + 1, rake_step)\n",
    "    rake_tmp = fm['np2']['rake']\n",
    "    rake2 = np.arange(rake_tmp - rake_sigma, rake_tmp + rake_sigma + 1, rake_step)\n",
    "\n",
    "    fm1 = np.array(np.meshgrid(stk1, dip1, rake1)).T.reshape(-1,3)\n",
    "    fm2 = np.array(np.meshgrid(stk2, dip2, rake2)).T.reshape(-1,3)\n",
    "    focal_mechanism = np.concatenate((fm1, fm2))\n",
    "    print('    Number of angle combinations = ' + str(focal_mechanism.shape[0]))\n",
    "\n",
    "    return focal_mechanism\n",
    "\n",
    "def compute_fault_size(magnitude):\n",
    "    \"\"\"\n",
    "    Fault dimensions (length, width and area) are converted from km to m.\n",
    "    \"\"\"\n",
    "    #TODO understand which scaling law to use in global\n",
    "\n",
    "    print('--> Computing fault size')\n",
    "\n",
    "    length = scalinglaw_WC(mag=magnitude, type_scala='M2L')\n",
    "    width = scalinglaw_WC(mag=magnitude, type_scala='M2W')\n",
    "    area = length * width\n",
    "    fault_size = np.vstack((length*1.e3, width*1.e3, area*1.e6)).T\n",
    "   \n",
    "    return fault_size\n",
    "\n",
    "def compute_slip(magnitude, fault_size, mu):\n",
    "    \"\"\"\n",
    "    Calculation of slip from magnitude by scalar seismic moment.\n",
    "\n",
    "    Scalar seismic moment: M0 = 10**(1.5*(magnitudo+10.7) \n",
    "                           Kanamori formula 1977 in dyne⋅cm (10−7 N⋅m)\n",
    "    Slip on fault        : D(m) = M0(Pa*m3) / area(m2)*mu(Pa)\n",
    "\n",
    "    \"\"\"\n",
    "    print('--> Computing slip')\n",
    "\n",
    "    area = fault_size[:,0]*fault_size[:,1]\n",
    "    scalar_moment = 10.**(1.5*(magnitude+10.7)) * 1.e-7\n",
    "    \n",
    "    return scalar_moment/(area*mu)\n",
    "\n",
    "def compute_mag_probability(idx, event_parameters, mag_discretization):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    ev_mag_sigma = event_parameters['MagSigma']\n",
    "    ev_mag       = event_parameters['mag']\n",
    "\n",
    "    print('--> Computing magnitude cumulative distribution')\n",
    "\n",
    "    a = mag_discretization[0:-1]\n",
    "    b = mag_discretization[1:]\n",
    "    c = np.add(a, b) * 0.5\n",
    "\n",
    "    lower = np.insert(c, 0, -np.inf)\n",
    "    upper = np.insert(c, c.size, np.inf)\n",
    "\n",
    "    lower_probility_norm  = norm.cdf(lower, ev_mag, ev_mag_sigma)\n",
    "    upper_probility_norm  = norm.cdf(upper, ev_mag, ev_mag_sigma)\n",
    "\n",
    "    magnitude_probability = np.subtract(upper_probility_norm, lower_probility_norm)\n",
    "\n",
    "    magnitude_probability = magnitude_probability[idx]\n",
    "\n",
    "    return magnitude_probability\n",
    "\n",
    "def compute_pos_probability(event_parameters, ensemble):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    print('--> Computing position probabilities')\n",
    "\n",
    "    magnitudes = ensemble['magnitude']\n",
    "    grid_3d    = ensemble['grid_3d']\n",
    "\n",
    "    mu = event_parameters['PosMean_3d']\n",
    "\n",
    "    n_points = grid_3d.shape[0]\n",
    "    n_mag = len(magnitudes)\n",
    "    position_probability = np.zeros((n_mag, n_points))\n",
    "    for imag,mag in enumerate(magnitudes):\n",
    "        # Compute vertical half_width with respect the magnitude\n",
    "        v_hwidth = correct_BS_vertical_position(mag = mag)\n",
    "        h_hwidth = correct_BS_horizontal_position(mag = mag)\n",
    "\n",
    "        co = copy.deepcopy(event_parameters['PosCovMat_3dm'])\n",
    "        # Correct  Covariance matrix\n",
    "        co[0,0] = co[0,0] + h_hwidth**2\n",
    "        co[1,1] = co[1,1] + h_hwidth**2\n",
    "        co[2,2] = co[2,2] + v_hwidth**2\n",
    "        tmp_prob_points = NormMultiDvec(x = grid_3d, mu = mu, sigma = co)\n",
    "        normfact = np.sum(tmp_prob_points)\n",
    "        #TODO normalization for each mag (or normalize once outside of the loop?)\n",
    "        position_probability[imag] = tmp_prob_points / normfact   \n",
    "   \n",
    "    return position_probability\n",
    "\n",
    "def compute_mech_probability(ensemble):\n",
    "\n",
    "    print('--> Computing focal mechanism probabilities')\n",
    "    \n",
    "    # TODO EQUIPROBABILITY FOR ALL MECHANISMS\n",
    "    n_scenarios, _ = ensemble['focal_mechanism'].shape\n",
    "    mechanism_probabilities = np.ones((n_scenarios))/n_scenarios              \n",
    "\n",
    "    return mechanism_probabilities\n",
    "\n",
    "def scenarios_parameters_and_probabilities(ensemble_probs, ensemble):\n",
    "    \"\"\"\n",
    "    ordered list of scenarios parameters for t-hysea simulations:\n",
    "       index, mag, lon, lat, depth, strike, dip, rake, length, area, slip\n",
    "       nparams: number of parameters (assigned manually as 11)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print('--> Computing the total probability for each scenario')\n",
    "\n",
    "    n_mag = len(ensemble['magnitude'])\n",
    "    n_points = ensemble['grid_3d'].shape[0]\n",
    "    n_foc_mech = ensemble['focal_mechanism'].shape[0]\n",
    "    #print(n_mag, n_points, n_foc_mech)\n",
    "    nscen = n_mag * n_points * n_foc_mech\n",
    "    print('Total number of scenarios = ' + str(nscen))\n",
    "\n",
    "    nparams = 12\n",
    "    scen_params = np.zeros((nscen, nparams))\n",
    "    scen_probs = np.zeros((nscen,3))\n",
    "    \n",
    "    iscen = 0\n",
    "    for imag in range(n_mag):\n",
    "        for ipoint in range(n_points):\n",
    "            for ifoc in range(n_foc_mech):\n",
    "                scen_params[iscen,0] = iscen + 1\n",
    "                scen_params[iscen,1] = 9999\n",
    "                scen_params[iscen,2] = ensemble['magnitude'][imag]\n",
    "                scen_params[iscen,3] = ensemble['position_geo_lon'][ipoint]\n",
    "                scen_params[iscen,4] = ensemble['position_geo_lat'][ipoint]\n",
    "                scen_params[iscen,5] = ensemble['grid_3d'][ipoint,2] / 1.e3    # m --> km\n",
    "                scen_params[iscen,6] = ensemble['focal_mechanism'][ifoc,0]\n",
    "                scen_params[iscen,7] = ensemble['focal_mechanism'][ifoc,1]\n",
    "                scen_params[iscen,8] = ensemble['focal_mechanism'][ifoc,2]\n",
    "                scen_params[iscen,9] = ensemble['fault_size'][imag,0] / 1.e3   # m --> km\n",
    "                scen_params[iscen,10] = ensemble['fault_size'][imag,2] / 1.e6  # m2 --> km2\n",
    "                scen_params[iscen,11] = ensemble['slip'][imag]\n",
    "\n",
    "                scen_probs[iscen,0] = ensemble_probs['magnitude'][imag]\n",
    "                scen_probs[iscen,1] = ensemble_probs['position'][imag,ipoint]\n",
    "                scen_probs[iscen,2] = ensemble_probs['focal_mechanism'][ifoc]\n",
    "\n",
    "                iscen += 1\n",
    "\n",
    "    scenario_parameters = scen_params\n",
    "    scenario_probability_pre_norm = scen_probs.prod(axis=1)\n",
    "\n",
    "    # print('--> Normalizing scenario probabilities')\n",
    "    #both prob_mag and prob_pos are normalized, normfact=1, maybe not needed!\n",
    "    normfact = np.sum(scenario_probability_pre_norm) \n",
    "    scenario_probability = scenario_probability_pre_norm / normfact\n",
    "    \n",
    "    # print(np.sort(scenario_probability)) \n",
    "    \n",
    "    return scenario_parameters, scenario_probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b461ffd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions are copied from the ptf_ellipsoid.py file\n",
    "\n",
    "def build_location_ellipsoid_objects(**kwargs):\n",
    "    \"\"\"\n",
    "    From ellipsedata.m\n",
    "    % Copyright (c) 2014, Hugo Gabriel Eyherabide, Department of Mathematics\n",
    "    % and Statistics, Department of Computer Science and Helsinki Institute\n",
    "    % for Information Technology, University of Helsinki, Finland.\n",
    "    % All rights reserved.\n",
    "\n",
    "    !!!! Difference with the original matlab function !!!!\n",
    "    sigma in this python function is a float\n",
    "    sigma in matlab is a vector\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ee                 = kwargs.get('event', 'None')\n",
    "    sigma              = kwargs.get('sigma', 'None')\n",
    "    seismicity_type    = kwargs.get('seismicity_type', 'None')\n",
    "   \n",
    "    # Number of points to set the 2d ellipse\n",
    "    nr_points = 1000\n",
    "    \n",
    "    sigma = float(sigma)\n",
    "\n",
    "    # 2d Covariant matrix, eigenvalues and eignevectors\n",
    "    if(seismicity_type == 'BS'):\n",
    "       cov_matrix   = np.array([ [ee['position_BS_sigma_yy']**2, 0], [0, ee['position_BS_sigma_xx']**2] ])\n",
    "    elif(seismicity_type == 'PS'):\n",
    "       cov_matrix   = np.array([ [ee['position_PS_sigma_yy']**2, 0], [0, ee['position_PS_sigma_xx']**2] ])\n",
    "    else:\n",
    "       raise Exception('No seismicity type found. Exit')\n",
    "       #sys.exit('No seismicity type found. Exit')\n",
    "\n",
    "    # Center of the ellipse\n",
    "    center = (ee['ee_utm'][1],ee['ee_utm'][0])\n",
    "\n",
    "    PV, PD = np.linalg.eigh(cov_matrix)\n",
    "    PV = np.sqrt(np.diag(PV))\n",
    "\n",
    "    # Build points of ellipse\n",
    "    theta = np.linspace(0,2*np.pi,nr_points)\n",
    "    elpt  = np.dot(np.transpose(np.array([np.cos(theta), np.sin(theta)])) , PV)\n",
    "    elpt  = np.dot(elpt, np.transpose(PD))\n",
    "\n",
    "    # Add uncertainty\n",
    "    elpt = elpt * sigma\n",
    "\n",
    "    # shift to the center\n",
    "    elpt    = np.transpose(elpt)\n",
    "    elpt[0] = elpt[0] + center[0]\n",
    "    elpt[1] = elpt[1] + center[1]\n",
    "    elpt    = np.transpose(elpt)\n",
    "\n",
    "    return elpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9771e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions are copied from the ptf_lambda_bsps_load.py\n",
    "def load_lambda_BSPS(sigma, ee_d):\n",
    "\n",
    "    d = dict()\n",
    "\n",
    "    ## Variables for lambda\n",
    "    d['lambdaBSPS']                                = {}\n",
    "    d['lambdaBSPS']['hypo_utm']                    = np.array([ee_d['ee_utm'][0], \\\n",
    "                                                               ee_d['ee_utm'][1], \\\n",
    "                                                               ee_d['depth'] ])\n",
    "    d['lambdaBSPS']['utmzone_hypo']                = ee_d['ee_utm'][2]\n",
    "    d['lambdaBSPS']['NormCov']                     = ee_d['PosCovMat_3d']\n",
    "    d['lambdaBSPS']['confid_lev']                  = norm.cdf(sigma) - norm.cdf(-1 * sigma)\n",
    "    d['lambdaBSPS']['dchi2']                       = distributions.chi2.ppf(d['lambdaBSPS']['confid_lev'], 3)\n",
    "    d['lambdaBSPS']['SD']                          = math.sqrt(d['lambdaBSPS']['dchi2'])\n",
    "    # d['lambdaBSPS']['mesh']                        = get_meshes(ee_d, data_folder)\n",
    "    d['lambdaBSPS']['covariance_epicenter_volume'] = get_cov_volume(ee_d['PosCovMat_3d'], d['lambdaBSPS']['SD'])\n",
    "    d['lambdaBSPS']['npts_mw']                     = get_npts_mw(d['lambdaBSPS']['covariance_epicenter_volume'])\n",
    "    d['lambdaBSPS']['gaussian_ellipsoid']          = get_gaussian_ellipsoid_3d(ee_d, ee_d['PosCovMat_3d'], d['lambdaBSPS']['SD'], d['lambdaBSPS']['npts_mw'])\n",
    "    d['lambdaBSPS']                                = get_gaussian_ellipsoid_tetraedons(d['lambdaBSPS'], ee_d)\n",
    "\n",
    "    return d['lambdaBSPS']\n",
    "\n",
    "def get_cov_volume(cov_matrix, std):\n",
    "\n",
    "    w, v = np.linalg.eig(cov_matrix)\n",
    "    l_major = std*np.sqrt(w[0]) * 1000.0\n",
    "    l_inter = std*np.sqrt(w[1]) * 1000.0\n",
    "    l_minor = std*np.sqrt(w[2]) * 1000.0\n",
    "\n",
    "    volume = (4./3.) * np.pi * l_major * l_inter * l_minor\n",
    "\n",
    "    return volume\n",
    "\n",
    "def get_npts_mw(volume):\n",
    "    \"\"\"\n",
    "    Calculate the number of points to define de ellipsoide.\n",
    "    Fitting function a*x**b found by F.Romano\n",
    "    \"\"\"\n",
    "\n",
    "    a         = 0.6211\n",
    "    b         = 0.4358\n",
    "    n_tetra   = 23382 \n",
    "    vol_tetra = 3.9990e+15\n",
    "\n",
    "    npts_mw   = np.ceil(a*(volume*n_tetra/vol_tetra)**b).astype(int)\n",
    "    npts_mw   = max(10, npts_mw)\n",
    "\n",
    "    return npts_mw\n",
    "\n",
    "def get_gaussian_ellipsoid_3d(ee, cov, std, npts): \n",
    "\n",
    "    center = [ee['ee_utm'][0], ee['ee_utm'][1], ee['depth']*-1000.0]\n",
    "\n",
    "    cov = cov*1e6\n",
    "    w, v = np.linalg.eigh(cov)\n",
    "    if np.any(w < 0):\n",
    "        print('Warning: negative eigenvalues')\n",
    "        w = max(w,0)\n",
    "    w = std * np.sqrt(w)    #get std of the cov matrix\n",
    "\n",
    "    volume = (4./3.) * np.pi * w[0] * w[1] * w[2]\n",
    "\n",
    "    # Make 3x 11x11 arrays\n",
    "    x, y, z = create_sphere(npts)\n",
    "\n",
    "    x = np.transpose(x)\n",
    "    y = np.transpose(y)\n",
    "    z = np.transpose(z)\n",
    "\n",
    "    # Flattern 11x11 array\n",
    "    ap = np.array([np.ravel(x), np.ravel(y), np.ravel(z)])\n",
    "\n",
    "    bp = np.dot(np.dot(v, np.diag(w)), ap) +  \\\n",
    "         np.transpose(np.tile(center, (np.shape(ap)[1], 1)))\n",
    "\n",
    "    xp = np.reshape(bp[0, :], np.shape(x))\n",
    "    yp = np.reshape(bp[1, :], np.shape(y))\n",
    "    zp = np.reshape(bp[2, :], np.shape(z))\n",
    "\n",
    "    ellipsoid = {'xp':xp, 'yp':yp, 'zp':zp, 'vol': volume}\n",
    "    print(\" --> Volume of the Gaussian Ellipsoid: {:.8e} [m^3]\".format(volume))\n",
    "\n",
    "    return ellipsoid\n",
    "\n",
    "def create_sphere(n_points=None, radius=None):\n",
    "    \"\"\"\n",
    "    Create a discrete 3D spheric surface (points)\n",
    "    Reference to create the shere:\n",
    "       https://it.mathworks.com/matlabcentral/answers/48240-surface-of-a-equation:\n",
    "       n = 100;\n",
    "        r = 1.5;\n",
    "        theta = (-n:2:n)/n*pi;\n",
    "        phi = (-n:2:n)'/n*pi/2;\n",
    "        cosphi = cos(phi); cosphi(1) = 0; cosphi(n+1) = 0;\n",
    "        sintheta = sin(theta); sintheta(1) = 0; sintheta(n+1) = 0;\n",
    "        x = r*cosphi*cos(theta);\n",
    "        y = r*cosphi*sintheta;\n",
    "        z = r*sin(phi)*ones(1,n+1);\n",
    "        surf(x,y,z)\n",
    "        xlabel('X'); ylabel('Y'); zlabel('Z')\n",
    "    \"\"\"\n",
    "    if radius is None:\n",
    "        radius = 1.0\n",
    "\n",
    "    if n_points is None:\n",
    "        n_points = 20\n",
    "\n",
    "    theta = np.matrix(np.arange(-1*n_points,n_points+1,2) / n_points * np.pi)\n",
    "    phi   = np.matrix(np.arange(-1*n_points,n_points+1,2) / n_points * np.pi / 2)\n",
    "    phi   = phi.transpose()\n",
    "\n",
    "    X = radius*np.matmul(np.cos(phi),np.cos(theta))\n",
    "    Y = radius*np.matmul(np.cos(phi),np.sin(theta))\n",
    "    Z = radius*np.matmul(np.sin(phi),np.matrix(np.ones(11)))\n",
    "\n",
    "    # Set to 0 the very small numbers\n",
    "    X[0] = 0\n",
    "    X[-1] = 0\n",
    "    Y[0] = 0\n",
    "    Y[-1] = 0\n",
    "    Y[:,0] = 0\n",
    "    Y[:,-1] = 0\n",
    "\n",
    "    return X,Y,Z\n",
    "\n",
    "def get_gaussian_ellipsoid_tetraedons(el, ee):\n",
    "    \"\"\"\n",
    "    From R. Tonini\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    xp = el['gaussian_ellipsoid']['xp']\n",
    "    yp = el['gaussian_ellipsoid']['yp']\n",
    "    zp = el['gaussian_ellipsoid']['zp'] #*-1.0\n",
    "\n",
    "    # array preparation for creating tetrahedrons\n",
    "    # This is like sss on matptf\n",
    "    sss = np.vstack([xp.flatten(), yp.flatten(), zp.flatten()]).transpose()\n",
    "    points_xyz = np.unique(sss, axis=0)\n",
    "    n_points, tmp = np.shape(points_xyz)\n",
    "\n",
    "    # lon lat conversion\n",
    "    points_ll = np.zeros((n_points, 3))\n",
    "    for i in range(n_points):\n",
    "        points_ll[i, [1, 0]] = utm.to_latlon(points_xyz[i, 0],\n",
    "                                             points_xyz[i, 1],\n",
    "                                             ee['ee_utm'][2], ee['ee_utm'][3])\n",
    "\n",
    "    points_ll[:, 2] = points_xyz[:, 2]\n",
    "\n",
    "    # Good but slower (0.0030319690704345703 <=> 0.0013072490692138672)\n",
    "    # from pyhull.delaunay import DelaunayTri\n",
    "    # tetrahedrons = np.asarray(DelaunayTri(points_ll).vertices)\n",
    "    # tetrahedron discretization (based on the points on the surface)\n",
    "    tessellation = scipy.spatial.Delaunay(points_ll)\n",
    "    tetrahedrons = tessellation.simplices\n",
    "\n",
    "    # computing barycenters\n",
    "    tetra_bar          = {}\n",
    "    tetra_bar[\"utm_x\"] = np.mean(points_xyz[tetrahedrons, 0], axis=1)\n",
    "    tetra_bar[\"utm_y\"] = np.mean(points_xyz[tetrahedrons, 1], axis=1)\n",
    "    tetra_bar[\"lon\"]   = np.mean(points_ll[tetrahedrons, 0], axis=1)\n",
    "    tetra_bar[\"lat\"]   = np.mean(points_ll[tetrahedrons, 1], axis=1)\n",
    "    tetra_bar[\"depth\"] = np.mean(points_ll[tetrahedrons, 2], axis=1)\n",
    "\n",
    "    tetra_xyz = np.column_stack((tetra_bar[\"utm_x\"],\n",
    "                                 tetra_bar[\"utm_y\"],\n",
    "                                 tetra_bar[\"depth\"]))\n",
    "\n",
    "    n_tetra = len(tetra_bar[\"lon\"])\n",
    "    print(\" --> N. Tetra in the Gaussian Ellipsoid: {0}\".format(n_tetra))\n",
    "\n",
    "    # computing tetrahedrons volume\n",
    "    volume = np.zeros((n_tetra))\n",
    "    for i in range(n_tetra):\n",
    "        mm = np.column_stack((points_xyz[tetrahedrons[i, :], :],\n",
    "                              np.array([1, 1, 1, 1])))\n",
    "        volume[i] = np.abs(np.linalg.det(mm)/6.)\n",
    "\n",
    "    volume_tot = np.sum(volume)\n",
    "    print(\" --> Volume of Tetra in the Gaussian Ellipsoid: %.8e [m^3]\" % volume_tot)\n",
    "\n",
    "    Vol_diff_perc = (el['gaussian_ellipsoid']['vol'] - volume_tot) / el['gaussian_ellipsoid']['vol']*100\n",
    "    print(\" --> Volume difference Gaussian <--> Tetra: %.2f [%%]\" % Vol_diff_perc)\n",
    "\n",
    "    el['tetra_bar']                 = tetra_bar\n",
    "    el['tetrahedrons']              = tetrahedrons\n",
    "    el['gaussian_ellipsoid_volume'] = volume_tot\n",
    "    el['volumes_elements']          = volume\n",
    "    el['tetra_xyz']                 = tetra_xyz\n",
    "\n",
    "    return el    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed96d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions are copied from the step3_run.py file\n",
    "\n",
    "def compute_hazard_curves(mih, prob_scenarios, n_pois, thresholds, sigma):\n",
    "\n",
    "    n_thr = len(thresholds)\n",
    "\n",
    "    hazard_curves_pois = np.zeros((n_pois, n_thr))\n",
    "\n",
    "    # print(n_pois, n_thr, n_scen)\n",
    "    # print(mih.shape, prob_scenarios.shape)\n",
    "\n",
    "    # hazard_mode = 'lognormal'\n",
    "    for ip in range(n_pois):\n",
    "\n",
    "            mih_at_poi = mih[:,ip]\n",
    "            ind_tmp = np.array(mih_at_poi == 0)\n",
    "            mih_at_poi[ind_tmp] = 1.e-12\n",
    "\n",
    "            mu = mih_at_poi\n",
    "            mu = mu.reshape(len(mu), 1)\n",
    "\n",
    "            cond_hazard_curve_tmp = 1 - scipy.stats.lognorm.cdf(thresholds, sigma, scale=mu).transpose()\n",
    "            hazard_curves_pois[ip,:] = np.sum(prob_scenarios*cond_hazard_curve_tmp, axis=1)\n",
    "\n",
    "    # # hazard_mode = 'lognormal_v1'\n",
    "    # mih_coo = scipy.sparse.coo_array(mih)\n",
    "    # print(\"Number of non-zero elements = {}\".format(len(mih_coo.data)))\n",
    "    # df_mihs = pd.DataFrame({\"id_scen\":mih_coo.row,\"id_poi\":mih_coo.col,\"mih_value\":mih_coo.data})\n",
    "    # df_prob_scenarios = pd.DataFrame(prob_scenarios)\\\n",
    "    #                             .reset_index()\\\n",
    "    #                             .rename(columns={'index':'id_scen',0:'prob_scen'})\n",
    "    # df_mihs = df_mihs.merge(df_prob_scenarios,how='left',left_on='id_scen', right_on='id_scen')\n",
    "\n",
    "    # for ith,threshold in enumerate(thresholds[:]):\n",
    "    #     df_mihs_thr = df_mihs.copy(deep=True)\n",
    "    #     col_name = 'prob_lognorm_{}'.format(threshold)\n",
    "    #     df_mihs_thr[col_name] = 1-scipy.stats.lognorm.cdf(threshold, sigma, scale=df_mihs_thr['mih_value']).transpose()\n",
    "    #     df_mihs_thr[col_name] = df_mihs_thr[col_name]*df_mihs_thr['prob_scen']\n",
    "    #     df_mihs_thr = df_mihs_thr.groupby(by='id_poi').agg({col_name:'sum'})\n",
    "    #     hazard_curves_pois[df_mihs_thr.index,ith]=df_mihs_thr[col_name].to_numpy()\n",
    "\n",
    "    return hazard_curves_pois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcf64df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions are copied from the step5_run.py file\n",
    "\n",
    "def plot_hazard_maps(points, hmaps, event_dict, map_label):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    proj = cartopy.crs.PlateCarree()\n",
    "    #cmap = plt.cm.magma_r\n",
    "    cmap = plt.cm.jet\n",
    "    ev_lon = event_dict['lon']\n",
    "    ev_lat = event_dict['lat']\n",
    "    ev_depth = event_dict['depth']\n",
    "    ev_mag = event_dict['mag']\n",
    "    ev_place = event_dict['place']\n",
    "\n",
    "    for key, hmap in hmaps.items():           \n",
    "                \n",
    "        print(\"mapping ... {}\".format(key))\n",
    "        fig = plt.figure(figsize=(16, 8))\n",
    "        # ax = plt.axes(projection=cartopy.crs.Mercator())\n",
    "        usemap_proj = cartopy.crs.PlateCarree(central_longitude=180)\n",
    "        ax = plt.axes(projection=usemap_proj)\n",
    "        coastline = cartopy.feature.GSHHSFeature(scale='low', levels=[1])\n",
    "        #coastline = cartopy.feature.GSHHSFeature(scale='high', levels=[1])\n",
    "        ax.add_feature(coastline, edgecolor='#000000', facecolor='#cccccc', linewidth=1)\n",
    "        ax.add_feature(cartopy.feature.BORDERS.with_scale('50m'))\n",
    "        ax.add_feature(cartopy.feature.STATES.with_scale('50m'))\n",
    "        ax.add_feature(cartopy.feature.OCEAN.with_scale('50m'))\n",
    "        gl = ax.gridlines(crs=proj, draw_labels=True, linewidth=1,\n",
    "                           color=\"#ffffff\", alpha=0.5, linestyle='-')\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "        gl.bottom_labels = True\n",
    "        gl.left_labels = True\n",
    "        gl.xformatter = cartopy.mpl.gridliner.LONGITUDE_FORMATTER\n",
    "        gl.yformatter = cartopy.mpl.gridliner.LATITUDE_FORMATTER\n",
    "        gl.xlabel_style = {'size': 14}\n",
    "        gl.ylabel_style = {'size': 14}\n",
    "\n",
    "        sc = ax.scatter(points[:,0], points[:,1], c=hmap, s=17, marker=\"o\", \n",
    "                    linewidths=0.75, edgecolors=\"#000000\", label=\" \",\n",
    "                    cmap=cmap, clip_on=True,# vmin=map_min, vmax=map_max, \n",
    "                    transform=proj, zorder=10, norm=matplotlib.colors.LogNorm(vmin=0.01, vmax=50))#(vmin=map_min, vmax=map_max))\n",
    "\n",
    "        ax.plot(ev_lon, ev_lat, linewidth=0, marker='*', markersize=14, \n",
    "                #markerfacecolor='#c0bfbc', markeredgecolor='#000000', \n",
    "                markerfacecolor='white', markeredgecolor='#000000', \n",
    "                transform=proj)\n",
    "\n",
    "        cbar = plt.colorbar(sc, shrink=0.75)\n",
    "        #cbar.ax.set_yticklabels(labels=cbar.ax.get_yticklabels(), fontsize=10)\n",
    "        cbar.set_label(label=f'(m)', size=12)\n",
    "        # ax.set_title(\"Hazard map - {0}\".format(key))\n",
    "        plt.suptitle(\"Hazard map - {0}\".format(key),fontsize=24)\n",
    "        plt.title(\"Epicentral Region: {0} \\n Event parameters: Lon={1}, Lat={2}, Depth={3}; Magnitude={4}\".format(ev_place, ev_lon, ev_lat, ev_depth, str(ev_mag)[:3] ),fontsize=18)\n",
    "        ax.set_xlabel(r'Longitude ($^\\circ$)', fontsize=14)\n",
    "        ax.set_ylabel(r'Latitude ($^\\circ$)', fontsize=14)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyfox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
