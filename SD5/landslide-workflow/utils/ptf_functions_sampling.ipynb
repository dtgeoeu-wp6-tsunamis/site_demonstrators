{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94cc30f3",
   "metadata": {},
   "source": [
    "This notebook contains the functions needed to sample the ensemble and reduce its size.   \n",
    "The sampling method to reduce the size of the ensemble is from\n",
    "Cordrie, L. , Selva, J. , Bernardi, F., Tonini, R., Romano, F., Volpe, M., Lorito, S. (2025). Dynamic management of uncertainty in rapid tsunami forecasting. Communications earth & environment, in press. https://doi.org/10.1038/s43247-025-02586-6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85ea43c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from math import radians, cos, sin, asin, sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0177e06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ensemble_sampling_SDE(**kwargs):\n",
    "\n",
    "    LongTermInfo   = kwargs.get('LongTermInfo', None)\n",
    "    negl_prob      = kwargs.get('negligible_prob', None)\n",
    "    pre_selection  = kwargs.get('pre_selection', None)\n",
    "    short_term     = kwargs.get('short_term', None)\n",
    "    regions        = kwargs.get('regions', None)\n",
    "    probability_scenarios = kwargs.get('proba_scenarios', None)\n",
    "    SDE_samp_scen         = kwargs.get('samp_scen', None)\n",
    "    samp_type             = kwargs.get('samp_type', None)\n",
    "\n",
    "    TotProbBS_all = np.sum(probability_scenarios['ProbScenBS'])\n",
    "    TotProbPS_all = np.sum(probability_scenarios['ProbScenPS'])\n",
    "    sampled_ensemble = {}\n",
    "\n",
    "    ### Beginning the creation of the Nth sampled ensemble ###\n",
    "    N=int(SDE_samp_scen)\n",
    "    NBS= int(TotProbBS_all*N) # NBS: number of scenarios sampled from the BS ensemble\n",
    "    NPS= N-NBS                # NPS: number of scenarios sampled from the PS ensemble\n",
    "    sampled_ensemble = set_if_compute_scenarios(short_term    = short_term,\n",
    "                                                negl_prob     = negl_prob)\n",
    "    \n",
    "    prob_len_BS = len(probability_scenarios['ProbScenBS'])\n",
    "    prob_len_PS = len(probability_scenarios['ProbScenPS'])\n",
    "\n",
    "    ### Creation of the array of cumulated probability intervals associated to the initial ensemble ###\n",
    "    intervals_ensemble_BS = np.zeros(prob_len_BS)\n",
    "    probBSnorm = probability_scenarios['ProbScenBS']/np.sum(probability_scenarios['ProbScenBS'])\n",
    "    prob_cum = 0\n",
    "    for i in range(prob_len_BS):\n",
    "        prob_cum=prob_cum+probBSnorm[i]\n",
    "        intervals_ensemble_BS[i]= prob_cum\n",
    "\n",
    "    ### Creation of the array of cumulated probability intervals associated to the initial ensemble ###\n",
    "    intervals_ensemble_PS = np.zeros(prob_len_PS)\n",
    "    probPSnorm = probability_scenarios['ProbScenPS']/np.sum(probability_scenarios['ProbScenPS'])\n",
    "    prob_cum = 0\n",
    "    for i in range(prob_len_PS):\n",
    "        prob_cum=prob_cum+probPSnorm[i]\n",
    "        intervals_ensemble_PS[i]= prob_cum\n",
    "\n",
    "    ### Initialization of the dictionaries ###\n",
    "    sampled_ensemble['prob_scenarios_bs_fact'] = np.zeros( (NBS,  5) )\n",
    "    sampled_ensemble['prob_scenarios_bs'] = np.zeros( (NBS) )\n",
    "    sampled_ensemble['prob_scenarios_ang'] = np.zeros( (NBS) )\n",
    "    sampled_ensemble['par_scenarios_bs'] = np.zeros(  (NBS, 11) )\n",
    "    sampled_ensemble['prob_scenarios_ps_fact'] = np.zeros( (NPS,  5) )\n",
    "    sampled_ensemble['prob_scenarios_ps'] = np.zeros( (NPS) )\n",
    "    sampled_ensemble['par_scenarios_ps'] = np.zeros(  (NPS,  7) )\n",
    "    sampled_ensemble['iscenbs']=np.zeros(NBS)\n",
    "    sampled_ensemble['iscenps']=np.zeros(NPS)\n",
    "\n",
    "    sampled_ensemble = bs_probability_scenarios_sampling(short_term         = short_term,\n",
    "                                                         pre_selection      = pre_selection,\n",
    "                                                         regions_files      = regions,\n",
    "                                                         prob_scenes        = probability_scenarios,\n",
    "                                                         samp_ens           = sampled_ensemble,\n",
    "                                                         Discretizations    = LongTermInfo['Discretizations'],\n",
    "    \t\t\t\t                \t                 NBS                = NBS,\n",
    "                                                         intervals_ensemble = intervals_ensemble_BS,\n",
    "                                                         samp_type          = samp_type)\n",
    "\n",
    "    sampled_ensemble = ps_probability_scenarios_sampling(short_term         = short_term,\n",
    "                                                         prob_scenes        = probability_scenarios,\n",
    "                                                         samp_ens           = sampled_ensemble,\n",
    "                                                         NPS                = NPS,\n",
    "                                                         samp_type          = samp_type,\n",
    "                                                         intervals_ensemble = intervals_ensemble_PS)\n",
    "    \n",
    "    if(sampled_ensemble == False):\n",
    "        return False\n",
    "\n",
    "    # Re-Normalize scenarios (to manage events outside nSigma, BS for large events, ...)\n",
    "    ProbScenBS = sampled_ensemble['prob_scenarios_bs_fact'].prod(axis=1)\n",
    "    ProbScenPS = sampled_ensemble['prob_scenarios_ps_fact'].prod(axis=1)\n",
    "    TotProbBS_preNorm = np.sum(ProbScenBS)\n",
    "    TotProbPS_preNorm = np.sum(ProbScenPS)\n",
    "    TotProb_preNorm   = TotProbBS_preNorm + TotProbPS_preNorm\n",
    "\n",
    "    # No scenarios bs or ps possible\n",
    "    if(TotProb_preNorm == 0):\n",
    "        return False\n",
    "    elif(TotProb_preNorm != 0):\n",
    "        ProbScenBS = ProbScenBS / TotProb_preNorm\n",
    "        ProbScenPS = ProbScenPS / TotProb_preNorm\n",
    "\n",
    "    TotBS=len(ProbScenBS)\n",
    "    TotPS=len(ProbScenPS)\n",
    "    Tot=TotBS+TotPS\n",
    "    ProbScenBS = np.ones(TotBS)\n",
    "    ProbScenPS = np.ones(TotPS)\n",
    "\n",
    "    ######### Re-initialisation of the probability ######\n",
    "    ## A uniform probability is attributed to all the new scenarios ##\n",
    "    ## The probability is then modified proportionally to the number of repetitions ##\n",
    "    sampled_ensemble['ProbScenBS'] = np.ones(TotBS)*1./Tot\n",
    "    sampled_ensemble['ProbScenPS'] = np.ones(TotPS)*1./Tot\n",
    "    \n",
    "    prob_angles_sum = np.sum(sampled_ensemble['prob_scenarios_ang'])\n",
    "    prob_angles_tot = sampled_ensemble['prob_scenarios_ang']/prob_angles_sum\n",
    "\n",
    "    ######### Duplication of scenarios beginning ##########\n",
    "    ## The numbers of duplicated scenarios are saved, then multiplied by their respective probability \n",
    "    ## and the duplicates erased from the ensemble\n",
    "\n",
    "    sample_unique_bs, test, counts_bs = np.unique(sampled_ensemble['iscenbs'],return_index=True,return_counts=True) \n",
    "    unique_par = sampled_ensemble['par_scenarios_bs'][test,:]\n",
    "    unique_fact = sampled_ensemble['prob_scenarios_bs_fact'][test,:]\n",
    "    unique_prob = sampled_ensemble['ProbScenBS'][test]\n",
    "    unique_ang = sampled_ensemble['prob_scenarios_ang'][test]\n",
    "    unique_name = sampled_ensemble['iscenbs'][test]\n",
    "    ProbScenBS = np.ones(len(unique_prob))*1./Tot\n",
    "    for itmp in range(len(unique_prob)):\n",
    "       iscenbs=unique_name[itmp]\n",
    "       indexbs=np.where(sample_unique_bs == iscenbs)\n",
    "       ProbScenBS[itmp]=unique_prob[itmp]*counts_bs[indexbs]\n",
    "\n",
    "    sampled_ensemble['par_scenarios_bs'] = unique_par\n",
    "    sampled_ensemble['prob_scenarios_bs_fact'] = unique_fact\n",
    "    sampled_ensemble['ProbScenBS'] = ProbScenBS \n",
    "    sampled_ensemble['relevant_scenarios_bs'] = np.unique(sampled_ensemble['par_scenarios_bs'][:,0])\n",
    "    ProbScenBS = sampled_ensemble['ProbScenBS'] \n",
    "\n",
    "    sample_unique_ps, test, counts_ps = np.unique(sampled_ensemble['iscenps'],return_index=True,return_counts=True)\n",
    "    unique_par = sampled_ensemble['par_scenarios_ps'][test,:]\n",
    "    unique_fact = sampled_ensemble['prob_scenarios_ps_fact'][test,:]\n",
    "    unique_prob = sampled_ensemble['ProbScenPS'][test]\n",
    "    unique_name = sampled_ensemble['iscenps'][test]\n",
    "    ProbScenPS = np.ones(len(unique_prob))*1./Tot\n",
    "    for itmp in range(len(unique_prob)):\n",
    "       iscenps=unique_name[itmp]\n",
    "       indexps=np.where(sample_unique_ps == iscenps)\n",
    "       ProbScenPS[itmp]=unique_prob[itmp]*counts_ps[indexps]\n",
    "\n",
    "    sampled_ensemble['par_scenarios_ps'] = unique_par\n",
    "    sampled_ensemble['prob_scenarios_ps_fact'] = unique_fact\n",
    "    sampled_ensemble['ProbScenPS'] = ProbScenPS\n",
    "    sampled_ensemble['iscenps'] = unique_name\n",
    "    sampled_ensemble['relevant_scenarios_ps'] = np.unique(sampled_ensemble['par_scenarios_ps'][:,0])\n",
    "\n",
    "    print('Number of sampled BS scenarios: {}'.format(len(sampled_ensemble['par_scenarios_bs'])))\n",
    "    print('Number of sampled PS scenarios: {}'.format(len(sampled_ensemble['par_scenarios_ps'])))\n",
    "\n",
    "    try:\n",
    "        max_idxBS = np.argmax(ProbScenBS)\n",
    "    except:\n",
    "        max_idxBS = -1\n",
    "    try:\n",
    "        max_ValBS = ProbScenBS[max_idxBS]\n",
    "    except:\n",
    "        max_ValBS = 0\n",
    "    try:\n",
    "        max_idxPS = np.argmax(ProbScenPS)\n",
    "    except:\n",
    "        max_idxPS = -1\n",
    "    try:\n",
    "        max_ValPS = ProbScenPS[max_idxPS]\n",
    "    except:\n",
    "        max_ValPS = 0\n",
    "\n",
    "    sampled_ensemble['best_scenarios'] = {'max_idxBS':max_idxBS, 'max_idxPS':max_idxPS, 'max_ValBS':max_ValBS, 'max_ValPS':max_ValPS}\n",
    "    \n",
    "    return sampled_ensemble\n",
    "\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    arr = np.asarray(array)\n",
    "    idx = 0\n",
    "    diff = arr-value\n",
    "    diff[diff<1e-26]=100.0\n",
    "    idx=diff.argmin()\n",
    "    return idx,array[idx]\n",
    "\n",
    "\n",
    "def bs_probability_scenarios_sampling(**kwargs):\n",
    "\n",
    "    short_term      = kwargs.get('short_term', None)\n",
    "    prob_scenes     = kwargs.get('prob_scenes', None)\n",
    "    samp_ens        = kwargs.get('samp_ens', None)\n",
    "    pre_selection   = kwargs.get('pre_selection', None)\n",
    "    Discretizations = kwargs.get('Discretizations', None)\n",
    "    region_files    = kwargs.get('regions_files', None)\n",
    "    NBS\t            = kwargs.get('NBS', None)\n",
    "    int_ens         = kwargs.get('intervals_ensemble', None)\n",
    "    samp_type       = kwargs.get('samp_type', None)\n",
    "\n",
    "    region_info     = dict()\n",
    "\n",
    "    if (samp_ens['BScomputedYN'] == False or short_term['BS_computed_YN'] == False or pre_selection['BS_scenarios'] == False):\n",
    "        samp_ens['nr_bs_scenarios'] = 0\n",
    "        return samp_ens\n",
    "    regions_nr = []\n",
    "\n",
    "    ### Generation of an array (size of the new ensemble) of random probability \n",
    "    if samp_type=='MC':\n",
    "       random_value = np.random.random(NBS)\n",
    "    if samp_type=='LH':\n",
    "       sampler = stats.qmc.LatinHypercube(d=1)\n",
    "       random_value = sampler.random(n=NBS)\n",
    "    \n",
    "    iscenbs=0\n",
    "    for i in random_value:\n",
    "        ### Each value is associated to a scenario that can be retrieved from the cumulative probability function\n",
    "        idx, proba = find_nearest(int_ens,i)\n",
    "        ### samp_ens corresponds to the new ensemble where the identification nb of each scenario in \n",
    "        ### the initial ensemble is saved in iscenbs, and the parameters and the probability as well\n",
    "        samp_ens['iscenbs'][iscenbs]=idx\n",
    "        samp_ens['prob_scenarios_bs'][iscenbs]=prob_scenes['ProbScenBS'][idx]\n",
    "        for j in range(5):\n",
    "            samp_ens['prob_scenarios_bs_fact'][iscenbs,j]=prob_scenes['prob_scenarios_bs_fact'][idx,j]\n",
    "        for j in range(11):\n",
    "            samp_ens['par_scenarios_bs'][iscenbs,j]=prob_scenes['par_scenarios_bs'][idx,j] \n",
    " \n",
    "        # Inside the original code the strike/dip/rake\n",
    "        # do not depend of the magnitude and position\n",
    "        latlon_1=prob_scenes['par_scenarios_bs'][idx,2]\n",
    "        latlon_0=prob_scenes['par_scenarios_bs'][idx,3]\n",
    "        bs2_pos = len(pre_selection['BS2_Position_Selection_inn'])\n",
    "        d_latlon=np.zeros((bs2_pos,2))\n",
    "        d_diff=np.zeros((bs2_pos))\n",
    "        for val in range(bs2_pos):\n",
    "                tmp_idx = pre_selection['BS2_Position_Selection_inn'][val]\n",
    "                d_latlon[val,:] = Discretizations['BS-2_Position']['Val'][tmp_idx].split()\n",
    "                d_diff[val] = haversine(latlon_1, latlon_0, d_latlon[val,0], d_latlon[val,1])\n",
    "        ipos_idx = int(np.argmin(d_diff))\n",
    "        ipos = pre_selection['BS2_Position_Selection_inn'][ipos_idx]\n",
    "        ireg = Discretizations['BS-2_Position']['Region'][ipos] \n",
    "        \n",
    "        if(ireg not in regions_nr):\n",
    "            region_info = load_region_infos_sampling(ireg         = ireg,\n",
    "                                                     region_info  = region_info,\n",
    "                                                     region_files = region_files)\n",
    "            regions_nr.append(ireg)\n",
    "        \n",
    "        RegMeanProb_BS4 = region_info[ireg]['BS4_FocMech_MeanProb_valNorm']\n",
    "        \n",
    "        if(RegMeanProb_BS4.size == 0):\n",
    "             print(' --> WARNING: region info %d is empty!!! {}'.format(ireg))\n",
    "        \n",
    "        ipos_reg = np.where(region_info[ireg]['BS4_FocMech_iPosInRegion'] == ipos+1)[1]\n",
    "        tmpProbAngles = RegMeanProb_BS4[ipos_reg[0]]\n",
    "        id_sel = 0\n",
    "        val_angles = prob_scenes['par_scenarios_bs'][idx,5]+100*prob_scenes['par_scenarios_bs'][idx,6]+10000*prob_scenes['par_scenarios_bs'][idx,7]\n",
    "        for angles_id in range(len(Discretizations['BS-4_FocalMechanism']['Val'])):\n",
    "            str_val,dip_val,rak_val = Discretizations['BS-4_FocalMechanism']['Val'][angles_id].split()\n",
    "            val_check = float(str_val)+100*float(dip_val)+10000*float(rak_val)\n",
    "            if abs(val_angles-val_check)<0.0001:\n",
    "               id_sel=angles_id\n",
    "        ProbAngles = tmpProbAngles[id_sel]\n",
    "        samp_ens['prob_scenarios_ang'][iscenbs]=ProbAngles\n",
    "\n",
    "        iscenbs=iscenbs+1\n",
    "\n",
    "    samp_ens['nr_bs_scenarios'] = np.shape(samp_ens['prob_scenarios_bs_fact'])[0]\n",
    "    return samp_ens\n",
    "\n",
    "\n",
    "def ps_probability_scenarios_sampling(**kwargs):\n",
    "\n",
    "    short_term         = kwargs.get('short_term', None)\n",
    "    prob_scenes        = kwargs.get('prob_scenes', None)\n",
    "    samp_ens           = kwargs.get('samp_ens', None)\n",
    "    NPS                = kwargs.get('NPS', None)\n",
    "    int_ens            = kwargs.get('intervals_ensemble', None)\n",
    "    samp_type          = kwargs.get('samp_type', None)\n",
    "\n",
    "    samp_ens['PScomputedYN'] == False\n",
    "    \n",
    "    if(samp_ens['PScomputedYN'] == False or short_term['PS_computed_YN'] == False):\n",
    "\n",
    "        samp_ens['PScomputedYN']    = False\n",
    "        short_term['PS_computed_YN']   = False\n",
    "        samp_ens['nr_ps_scenarios'] = 0\n",
    "\n",
    "        return samp_ens\n",
    "\n",
    "    ### Generation of an array (size of the new ensemble) of random probability \n",
    "    if samp_type=='MC':\n",
    "       random_value = np.random.random(NPS)\n",
    "    if samp_type=='LH':\n",
    "       sampler = stats.qmc.LatinHypercube(d=1)\n",
    "       random_value = sampler.random(n=NPS)\n",
    "\n",
    "    iscenps=0\n",
    "    for i in random_value:\n",
    "        ### Each value is associated to a scenario that can be retrieved from the cumulative probability function\n",
    "        idx,proba = find_nearest(int_ens,i)\n",
    "        ### samp_ens corresponds to the new ensemble where the identification nb of each scenario in \n",
    "        ### the initial ensemble is saved in iscenbs, and the parameters and the probability as well\n",
    "        samp_ens['iscenps'][iscenps]=idx\n",
    "        samp_ens['prob_scenarios_ps'][iscenps]=prob_scenes['ProbScenPS'][idx]\n",
    "        for j in range(5):\n",
    "            samp_ens['prob_scenarios_ps_fact'][iscenps,j]=prob_scenes['prob_scenarios_ps_fact'][idx,j]\n",
    "        for j in range(7):\n",
    "            samp_ens['par_scenarios_ps'][iscenps,j]=prob_scenes['par_scenarios_ps'][idx,j]\n",
    "        iscenps=iscenps+1\n",
    "\n",
    "    samp_ens['nr_ps_scenarios'] = np.shape(samp_ens['prob_scenarios_ps_fact'])[0]\n",
    "\n",
    "    return samp_ens\n",
    "\n",
    "\n",
    "def load_region_infos_sampling(**kwargs):\n",
    "\n",
    "    ireg        = kwargs.get('ireg', None)\n",
    "    files       = kwargs.get('region_files', None)\n",
    "    region_info = kwargs.get('region_info', None)\n",
    "\n",
    "    info = np.load(files['ModelsProb_Region_files'][ireg-1], allow_pickle=True).item()\n",
    "    region_info[ireg] = info\n",
    "\n",
    "    return region_info\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    # Radius of earth in kilometers is 6371\n",
    "    km = 6371* c\n",
    "    return km\n",
    "\n",
    "def set_if_compute_scenarios(**kwargs):\n",
    "\n",
    "    short_term = kwargs.get('short_term', None)\n",
    "    negl_prob = kwargs.get('negl_prob', None)\n",
    "\n",
    "    out = dict()\n",
    "    out['nr_ps_scenarios'] = 0\n",
    "    out['nr_bs_scenarios'] = 0\n",
    "    BScomputedYN = False\n",
    "    PScomputedYN = False\n",
    "\n",
    "    tmpbs = (short_term['magnitude_probability'] * short_term['RatioBSonTot']).sum()\n",
    "    tmpps = (short_term['magnitude_probability'] * short_term['RatioPSonTot']).sum()\n",
    "    if(tmpbs > negl_prob):\n",
    "        BScomputedYN = True\n",
    "    if(tmpps > negl_prob):\n",
    "        PScomputedYN = True\n",
    "\n",
    "    out['BScomputedYN'] = BScomputedYN\n",
    "    out['PScomputedYN'] = PScomputedYN\n",
    "\n",
    "    return out\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
